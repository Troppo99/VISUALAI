{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reader = imageio.get_reader(r'C:\\xampp\\htdocs\\VISUALAI\\assets\\video\\walking people.mp4')\n",
    "prev_frame = None\n",
    "\n",
    "for frame in reader:\n",
    "    gray = np.mean(frame, axis=2)\n",
    "    if prev_frame is None:\n",
    "        prev_frame = gray\n",
    "        continue\n",
    "    diff = np.abs(gray - prev_frame)\n",
    "    mask = diff > 30\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.pause(0.001)\n",
    "    prev_frame = gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import supervision as sv\n",
    "from inference import get_model\n",
    "from PIL import Image\n",
    "from PIL.ImageFile import ImageFile\n",
    "\n",
    "\n",
    "def load_image_from_url(url: str) -> ImageFile:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # check if the request was successful\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    return image\n",
    "\n",
    "\n",
    "# load the image from an url\n",
    "image = load_image_from_url(\"https://media.roboflow.com/inference/people-walking.jpg\")\n",
    "\n",
    "# load a pre-trained yolov8n model\n",
    "model = get_model(model_id=\"yolov8n-640\")\n",
    "\n",
    "# run inference on our chosen image, image can be a url, a numpy array, a PIL image, etc.\n",
    "results = model.infer(image)[0]\n",
    "\n",
    "# load the results into the supervision Detections api\n",
    "detections = sv.Detections.from_inference(results)\n",
    "\n",
    "# create supervision annotators\n",
    "bounding_box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# annotate the image with our inference results\n",
    "annotated_image = bounding_box_annotator.annotate(scene=image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "# display the image\n",
    "sv.plot_image(annotated_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
