{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, os\n",
    "\n",
    "\n",
    "def detect_gaps(img_path):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    _, bin_img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    skel = np.zeros(bin_img.shape, np.uint8)\n",
    "    temp = np.zeros(bin_img.shape, np.uint8)\n",
    "    eroded = np.zeros(bin_img.shape, np.uint8)\n",
    "    elem = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "    done = False\n",
    "    while not done:\n",
    "        eroded = cv2.erode(bin_img, elem)\n",
    "        temp = cv2.dilate(eroded, elem)\n",
    "        temp = cv2.subtract(bin_img, temp)\n",
    "        cv2.bitwise_or(skel, temp, skel)\n",
    "        bin_img = eroded.copy()\n",
    "        if cv2.countNonZero(bin_img) == 0:\n",
    "            done = True\n",
    "\n",
    "    gap_points = []\n",
    "    rows, cols = skel.shape\n",
    "    for r in range(1, rows - 1):\n",
    "        for c in range(1, cols - 1):\n",
    "            if skel[r, c] == 255:\n",
    "                area = skel[r - 1 : r + 2, c - 1 : c + 2]\n",
    "                if cv2.countNonZero(area) == 2:\n",
    "                    gap_points.append((c, r))\n",
    "\n",
    "    out = cv2.imread(img_path)\n",
    "    for i in range(len(gap_points) - 1):\n",
    "        x1, y1 = gap_points[i]\n",
    "        x2, y2 = gap_points[i + 1]\n",
    "        dist = np.hypot(x2 - x1, y2 - y1)\n",
    "        if dist < 50:\n",
    "            mx = (x1 + x2) // 2\n",
    "            my = (y1 + y2) // 2\n",
    "            cv2.circle(out, (mx, my), 10, (0, 0, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Hasil Gap Detection\", out)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "detect_gaps(r\"C:\\xampp\\htdocs\\VISUALAI\\website-django\\inspection\\static\\images\\test\\disconnected.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "\n",
    "def resize(img, target_w):\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (target_w, int(h * target_w / w)))\n",
    "\n",
    "\n",
    "def binary_frame_by_dominant_colors(img):\n",
    "    data = img.reshape((-1, 3)).astype(np.float32)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    ret, labels, centers = cv2.kmeans(data, 2, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    brightness = []\n",
    "    for center in centers:\n",
    "        b, g, r = center\n",
    "        brightness.append(0.114 * b + 0.587 * g + 0.299 * r)\n",
    "    idx_bright = np.argmax(brightness)\n",
    "    binary = np.where(labels.flatten() == idx_bright, 255, 0).astype(np.uint8)\n",
    "    binary = binary.reshape(img.shape[:2])\n",
    "    return cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "w_target = 360\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    binary = binary_frame_by_dominant_colors(frame)\n",
    "    f1 = resize(frame, w_target)\n",
    "    f2 = resize(hsv, w_target)\n",
    "    f3 = resize(gray, w_target)\n",
    "    f4 = resize(binary, w_target)\n",
    "    top = np.hstack([f1, f2])\n",
    "    bottom = np.hstack([f3, f4])\n",
    "    grid = np.vstack([top, bottom])\n",
    "    cv2.imshow(\"Grid\", grid)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"n\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def detect_c_breaks_bbox(img_path, gap_threshold=20):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Jika huruf lebih gelap, pakai THRESH_BINARY, sesuaikan\n",
    "    _, bin_img = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Cari connected components\n",
    "    # stats: [x, y, width, height, area]\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(bin_img, connectivity=8)\n",
    "\n",
    "    # label 0 = background, sisanya objek\n",
    "    bboxes = []\n",
    "    for label_id in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[label_id]\n",
    "        if area > 10:\n",
    "            bboxes.append((x, y, x + w, y + h))  # (left, top, right, bottom)\n",
    "\n",
    "    if len(bboxes) <= 1:\n",
    "        print(\"Tidak terdeteksi lebih dari 1 huruf C, dianggap PASS.\")\n",
    "        cv2.imshow(\"Result\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "    # Urutkan berdasarkan top (y)\n",
    "    bboxes.sort(key=lambda b: b[1])\n",
    "\n",
    "    # Periksa gap di antara bounding box berurutan\n",
    "    # bottom dari box atas = b[3], top dari box bawah = b'[1]\n",
    "    putus_detected = False\n",
    "    for i in range(len(bboxes) - 1):\n",
    "        leftA, topA, rightA, bottomA = bboxes[i]\n",
    "        leftB, topB, rightB, bottomB = bboxes[i + 1]\n",
    "\n",
    "        distance = topB - bottomA\n",
    "        if distance > gap_threshold:\n",
    "            putus_detected = True\n",
    "            # Tentukan titik tengah gap\n",
    "            # X ambil rata-rata tengah bounding box A dan B\n",
    "            midX_A = (leftA + rightA) // 2\n",
    "            midX_B = (leftB + rightB) // 2\n",
    "            midX_gap = (midX_A + midX_B) // 2\n",
    "\n",
    "            # Y di tengah jarak antara bottomA dan topB\n",
    "            midY_gap = bottomA + distance // 2\n",
    "\n",
    "            cv2.circle(img, (midX_gap, midY_gap), 10, (0, 0, 255), 3)\n",
    "\n",
    "    if putus_detected:\n",
    "        print(\"WARNING: Ada huruf C terputus. Lingkaran merah menunjukkan lokasi gap.\")\n",
    "    else:\n",
    "        print(\"PASS: Tidak ada gap berarti di antara huruf C.\")\n",
    "    cv2.imshow(\"Result\", img)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "detect_c_breaks_bbox(r\"C:\\xampp\\htdocs\\VISUALAI\\website-django\\inspection\\static\\images\\test\\disconnected.jpg\", gap_threshold=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, cvzone\n",
    "\n",
    "\n",
    "def detect_c_breaks_bbox_red(frame, gap_threshold=20):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_red1 = np.array([0, 70, 70])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 70, 70])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    bboxes = []\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > 10:\n",
    "            bboxes.append((x, y, x + w, y + h))\n",
    "    if len(bboxes) <= 1:\n",
    "        return frame, False\n",
    "\n",
    "    bboxes.sort(key=lambda b: b[1])\n",
    "    putus = False\n",
    "    for i in range(len(bboxes) - 1):\n",
    "        lA, tA, rA, bA = bboxes[i]\n",
    "        lB, tB, rB, bB = bboxes[i + 1]\n",
    "        distance = tB - bA\n",
    "        if distance > gap_threshold:\n",
    "            putus = True\n",
    "            mx_gap = ((lA + rA) // 2 + (lB + rB) // 2) // 2\n",
    "            my_gap = bA + distance // 2\n",
    "            cv2.circle(frame, (mx_gap, my_gap), 10, (0, 0, 255), 3)\n",
    "    return frame, putus\n",
    "\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        print(\"No camera found.\")\n",
    "        return\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        result_frame, is_broken = detect_c_breaks_bbox_red(frame, gap_threshold=30)\n",
    "        if is_broken:\n",
    "            # cv2.putText(result_frame, \"REJECT: Ada Jahitan Terlewat\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cvzone.putTextRect(result_frame, \"Reject: Ada Jahitan Terlewat\", (20, 40), 1, 2, offset=5, border=2, colorR=(0, 255, 255), colorT=(0, 0, 0), colorB=(255, 255, 255))\n",
    "        else:\n",
    "            # cv2.putText(result_frame, \"GOOD: Tidak Ada Jahitan Terlewat\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cvzone.putTextRect(result_frame, \"Good: Tidak Ada Jahitan Terlewat\", (20, 40), 1, 2, offset=5, border=2, colorR=(0, 255, 0), colorT=(0, 0, 0), colorB=(255, 255, 255))\n",
    "        cv2.imshow(\"C Break Detection (Red)\", result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"n\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "\n",
    "def resize(img, target_w):\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (target_w, int(h * target_w / w)))\n",
    "\n",
    "\n",
    "def get_red_mask(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_red1 = np.array([0, 70, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 70, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "    return red_mask\n",
    "\n",
    "\n",
    "def enforce_dominant_line(img, red_mask):\n",
    "    edges = cv2.Canny(red_mask, 50, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=30, maxLineGap=10)\n",
    "    mask = np.ones_like(red_mask, dtype=np.uint8) * 255\n",
    "    if lines is not None:\n",
    "        longest_line = None\n",
    "        max_length = 0\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            length = np.hypot(x2 - x1, y2 - y1)\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "                longest_line = (x1, y1, x2, y2)\n",
    "        if longest_line is not None:\n",
    "            x1, y1, x2, y2 = longest_line\n",
    "            cv2.line(mask, (x1, y1), (x2, y2), 0, 5)\n",
    "    refined = np.where(mask[..., None] == 0, 0, img)\n",
    "    return refined\n",
    "\n",
    "\n",
    "w_target = 360\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    red_mask = get_red_mask(frame)\n",
    "    refined = enforce_dominant_line(frame.copy(), red_mask)\n",
    "    f1 = resize(frame, w_target)  # Citra asli\n",
    "    f2 = resize(cv2.cvtColor(red_mask, cv2.COLOR_GRAY2BGR), w_target)  # Mask merah\n",
    "    f3 = resize(refined, w_target)  # Citra dengan garis dominan\n",
    "    grid = np.hstack([f1, f2, f3])\n",
    "    cv2.imshow(\"Deteksi Garis Berdasarkan Warna\", grid)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"n\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, torch, kornia\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def resize(img, target_w):\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (target_w, int(h * target_w / w)))\n",
    "\n",
    "def get_red_mask_tensor_white_fabric(frame):\n",
    "    img_tensor = torch.from_numpy(frame).to(device, dtype=torch.float32)\n",
    "    img_tensor = img_tensor[..., [2, 1, 0]]\n",
    "    R = img_tensor[..., 0]\n",
    "    G = img_tensor[..., 1]\n",
    "    B = img_tensor[..., 2]\n",
    "    red_mask = (R > 100) & ((R - G) > 30) & ((R - B) > 30)\n",
    "    red_mask = red_mask.to(torch.uint8) * 255\n",
    "    return red_mask.cpu().numpy()\n",
    "\n",
    "def enforce_dominant_line(img, red_mask):\n",
    "    edges = cv2.Canny(red_mask, 50, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=30, maxLineGap=10)\n",
    "\n",
    "    mask = np.ones_like(red_mask, dtype=np.uint8) * 255\n",
    "    if lines is not None:\n",
    "        longest_line = None\n",
    "        max_length = 0\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            length = np.hypot(x2 - x1, y2 - y1)\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "                longest_line = (x1, y1, x2, y2)\n",
    "        if longest_line is not None:\n",
    "            x1, y1, x2, y2 = longest_line\n",
    "            cv2.line(mask, (x1, y1), (x2, y2), 0, 5)\n",
    "    refined = np.where(mask[..., None] == 0, 0, img)\n",
    "    return refined\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "w_target = 360\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    red_mask = get_red_mask_tensor_white_fabric(frame)\n",
    "    refined = enforce_dominant_line(frame.copy(), red_mask)\n",
    "\n",
    "    f1 = resize(frame, w_target)\n",
    "    f2 = resize(cv2.cvtColor(red_mask, cv2.COLOR_GRAY2BGR), w_target)\n",
    "    f3 = resize(refined, w_target)\n",
    "\n",
    "    grid = np.hstack([f1, f2, f3])\n",
    "    cv2.imshow(\"Deteksi Garis Berdasarkan Warna\", grid)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"n\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Computation : Add New Custom Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, torch, kornia\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def resize(img, w):\n",
    "    h, _ = img.shape[:2]\n",
    "    return cv2.resize(img, (w, int(h * w / img.shape[1])))\n",
    "\n",
    "\n",
    "def get_color_mask_tensor(frame, color=\"red\"):\n",
    "    img = torch.from_numpy(frame).float().to(device)[..., [2, 1, 0]]\n",
    "    R, G, B = img[..., 0], img[..., 1], img[..., 2]\n",
    "    if color == \"red\":\n",
    "        mask = (R > 100) & ((R - G) > 30) & ((R - B) > 30)\n",
    "    elif color == \"yellow\":\n",
    "        mask = (R > 150) & (G > 150) & (B > 150)\n",
    "    else:\n",
    "        mask = torch.zeros_like(R, dtype=torch.bool)\n",
    "    return (mask * 255).byte().cpu().numpy()\n",
    "\n",
    "\n",
    "def enforce_dominant_line(img, mask):\n",
    "    edges = cv2.Canny(mask, 50, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, 30, 10)\n",
    "    m = np.ones_like(mask) * 255\n",
    "    if lines is not None:\n",
    "        mx, ln = 0, None\n",
    "        for l in lines:\n",
    "            x1, y1, x2, y2 = l[0]\n",
    "            dist = np.hypot(x2 - x1, y2 - y1)\n",
    "            if dist > mx:\n",
    "                mx, ln = dist, (x1, y1, x2, y2)\n",
    "        if ln:\n",
    "            x1, y1, x2, y2 = ln\n",
    "            cv2.line(m, (x1, y1), (x2, y2), 0, 5)\n",
    "    return np.where(m[..., None] == 0, 0, img)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)  # ganti ke 1 bila diinginkan\n",
    "w_target = 360\n",
    "target_color = \"yellow\"  # ubah ke 'red' atau 'yellow'\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    mask = get_color_mask_tensor(frame, color=target_color)\n",
    "    refined = enforce_dominant_line(frame.copy(), mask)\n",
    "    f1 = resize(frame, w_target)\n",
    "    f2 = resize(cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR), w_target)\n",
    "    f3 = resize(refined, w_target)\n",
    "    cv2.imshow(\"Color-based Line Detection\", np.hstack([f1, f2, f3]))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"n\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "img = cv2.imread(r\"C:\\xampp\\htdocs\\VISUALAI\\website-django\\inspection\\static\\images\\test\\rapid_test.jpg\")\n",
    "img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "h, w = img.shape[:2]\n",
    "data = img.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "k = 2\n",
    "km = KMeans(n_clusters=k, random_state=42).fit(data)\n",
    "labels = km.labels_.reshape(h, w)\n",
    "\n",
    "largest_label = np.bincount(labels.flatten()).argmax()\n",
    "mask = (labels == largest_label).astype(np.uint8) * 255\n",
    "\n",
    "cv2.imshow(\"Dominant-Binary\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    original_img = frame.copy()\n",
    "    kernel_slide = 0\n",
    "    \n",
    "    blurred_img = cv2.GaussianBlur(frame, (kernel_slide, kernel_slide), 5)\n",
    "    h, w = blurred_img.shape[:2]\n",
    "    data = blurred_img.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "    k = 2\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(data)\n",
    "    labels = km.labels_.reshape(h, w)\n",
    "\n",
    "    largest_label = np.bincount(labels.flatten()).argmax()\n",
    "    mask = (labels == largest_label).astype(np.uint8) * 255\n",
    "\n",
    "    cv2.namedWindow(\"ori-blur-bin\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"ori-blur-bin\", (1280, 360))\n",
    "\n",
    "    cv2.imshow(\"ori-blur-bin\", np.hstack([original_img, blurred_img, cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)]))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"n\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
