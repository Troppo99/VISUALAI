{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMAGE CONVERTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "\n",
    "def equalize(img_org):\n",
    "    img_tmp = cv2.cvtColor(img_org, cv2.COLOR_BGR2GRAY)\n",
    "    img_tmp = cv2.equalizeHist(img_tmp)\n",
    "    count = np.array([[0, 0], [1279, 0], [1279, 340], [0, 340]])\n",
    "    img_tmp = cv2.fillPoly(img_tmp, pts=[count], color=(0))\n",
    "    return img_tmp\n",
    "\n",
    "\n",
    "def yellow(img_org):\n",
    "    img_hsv = cv2.cvtColor(img_org, cv2.COLOR_BGR2HSV)\n",
    "    lower_color = np.array([15, 100, 50], np.uint8)\n",
    "    upper_color = np.array([40, 200, 200], np.uint8)\n",
    "    img_mask = cv2.inRange(img_hsv, lower_color, upper_color)\n",
    "    img_tmp = cv2.bitwise_and(img_hsv, img_hsv, mask=img_mask)\n",
    "    img_tmp = cv2.cvtColor(img_tmp, cv2.COLOR_BGR2GRAY)\n",
    "    ret, img_tmp = cv2.threshold(img_tmp, 10, 256, cv2.THRESH_BINARY)\n",
    "    count = np.array([[0, 0], [1279, 0], [1279, 340], [0, 340]])\n",
    "    img_tmp = cv2.fillPoly(img_tmp, pts=[count], color=(0))\n",
    "    return img_tmp\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    img_equalize = equalize(frame)\n",
    "    img_yellow = yellow(frame)\n",
    "    img_or = cv2.bitwise_or(img_equalize, img_yellow)\n",
    "    img_blur = cv2.blur(img_or, ksize=(5, 5))\n",
    "    img_canny = cv2.Canny(img_blur, 200, 255, apertureSize=3)\n",
    "\n",
    "    # cv2.imshow('frame', frame)\n",
    "    # cv2.imshow(\"img_equalize\", img_equalize)\n",
    "    # cv2.imshow(\"img_yellow\", img_yellow)\n",
    "    # cv2.imshow(\"img_or\", img_or)\n",
    "    # cv2.imshow(\"img_blur\", img_blur)\n",
    "    cv2.imshow(\"img_canny\", img_canny)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('n'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "\n",
    "# Buat gambar hitam\n",
    "img = np.zeros((400, 400, 3), dtype=np.uint8)\n",
    "\n",
    "# Definisikan titik-titik poligon\n",
    "pts = np.array([[50, 50], [300, 50], [200, 300]], np.int32)\n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "# Isi poligon dengan warna hijau\n",
    "cv2.fillPoly(img, [pts], (0, 255, 0))\n",
    "\n",
    "cv2.imshow(\"Filled Polygon\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "\n",
    "def equalize(img):\n",
    "    img_tmp = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_tmp = cv2.equalizeHist(img_tmp)\n",
    "    w = 600\n",
    "    h = 400\n",
    "    x1 = round(640 - 0.5 * w)\n",
    "    y1 = round(360 - 0.5 * h)\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    poly = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])\n",
    "    mask = np.zeros_like(img_tmp)\n",
    "    cv2.fillPoly(mask, [poly], 255)\n",
    "    return cv2.bitwise_and(img_tmp, mask)\n",
    "\n",
    "\n",
    "def yellow(img_org):\n",
    "    img_hsv = cv2.cvtColor(img_org, cv2.COLOR_BGR2HSV)\n",
    "    lower_color = np.array([40, 50, 50], np.uint8)\n",
    "    upper_color = np.array([80, 255, 255], np.uint8)\n",
    "    img_mask = cv2.inRange(img_hsv, lower_color, upper_color)\n",
    "    img_tmp = cv2.bitwise_and(img_org, img_org, mask=img_mask)\n",
    "    img_tmp = cv2.cvtColor(img_tmp, cv2.COLOR_BGR2GRAY)\n",
    "    ret, img_tmp = cv2.threshold(img_tmp, 10, 256, cv2.THRESH_BINARY)\n",
    "    w = 600\n",
    "    h = 400\n",
    "    x1 = round(640 - 0.5 * w)\n",
    "    y1 = round(360 - 0.5 * h)\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    poly = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])\n",
    "    mask = np.zeros_like(img_tmp)\n",
    "    cv2.fillPoly(mask, [poly], 255)\n",
    "    return cv2.bitwise_and(img_tmp, mask)\n",
    "\n",
    "\n",
    "img = cv2.imread(r\"C:\\xampp\\htdocs\\VISUALAI\\website-django\\inspection\\src\\core\\img\\no-lighting.jpg\")\n",
    "print(img.shape)\n",
    "img_eq = equalize(img)\n",
    "img_yl = yellow(img)\n",
    "img_or = cv2.bitwise_or(img_eq, img_yl)\n",
    "cv2.imshow(\"image\", img_or)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SKIP DETECTOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, cv2, numpy as np, time, threading\n",
    "import cvzone\n",
    "from shapely.geometry import Polygon, Point\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class SkipDetector:\n",
    "    def __init__(self, image_file, camera_name, window_size=(960, 540)):\n",
    "        self.image_file = image_file\n",
    "        self.camera_name = camera_name\n",
    "        self.window_size = window_size\n",
    "        self.rois = self.camera_config()\n",
    "        self.window_name = f\"Inspection: {self.camera_name}\"\n",
    "\n",
    "    def camera_config(self):\n",
    "        with open(r\"\\\\10.5.0.3\\VISUALAI\\website-django\\inspection\\static\\resources\\conf\\camera_config_inspection.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        scaled_rois = []\n",
    "        rois_path = config[self.camera_name]\n",
    "        with open(rois_path, \"r\") as rois_file:\n",
    "            original_rois = json.load(rois_file)\n",
    "        for roi_group in original_rois:\n",
    "            scaled_group = []\n",
    "            for x, y in roi_group:\n",
    "                scaled_x = int(x * (960 / 1280))\n",
    "                scaled_y = int(y * (540 / 720))\n",
    "                scaled_group.append((scaled_x, scaled_y))\n",
    "            if len(scaled_group) >= 3:\n",
    "                polygon = Polygon(scaled_group)\n",
    "                if polygon.is_valid:\n",
    "                    scaled_rois.append(polygon)\n",
    "        return scaled_rois\n",
    "\n",
    "    def draw_rois(self, frame):\n",
    "        for roi in self.rois:\n",
    "            if roi.geom_type != \"Polygon\":\n",
    "                continue\n",
    "            pts = np.array(roi.exterior.coords, np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(frame, [pts], True, (0, 255, 0), 2)\n",
    "\n",
    "    def group_bboxes_by_row(self, bboxes, overlap_thresh=10):\n",
    "        rows = []\n",
    "        for bb in bboxes:\n",
    "            l, t, r, b = bb\n",
    "            placed = False\n",
    "            for row in rows:\n",
    "                l0, t0, r0, b0 = row[0]\n",
    "                if not (b < t0 - overlap_thresh or t > b0 + overlap_thresh):\n",
    "                    row.append(bb)\n",
    "                    placed = True\n",
    "                    break\n",
    "            if not placed:\n",
    "                rows.append([bb])\n",
    "        return rows\n",
    "\n",
    "    def detect_line_breaks_bbox_horizontal(self, frame, mask, gap_threshold=20):\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        num_labels, labels_cc, stats, _ = cv2.connectedComponentsWithStats(mask, 8)\n",
    "        bboxes = []\n",
    "        for i in range(1, num_labels):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area > 10:\n",
    "                bboxes.append((x, y, x + w, y + h))\n",
    "        if len(bboxes) <= 1:\n",
    "            return frame, False, False, 0\n",
    "        rows = self.group_bboxes_by_row(bboxes, overlap_thresh=10)\n",
    "        line_breaks = False\n",
    "        line_breaks_in_roi = False\n",
    "        circle_in_roi_count = 0\n",
    "        for row in rows:\n",
    "            row.sort(key=lambda b: b[0])\n",
    "            for i in range(len(row) - 1):\n",
    "                lA, tA, rA, bA = row[i]\n",
    "                lB, tB, rB, bB = row[i + 1]\n",
    "                distance = lB - rA\n",
    "                if distance > gap_threshold:\n",
    "                    line_breaks = True\n",
    "                    mx_gap = rA + distance // 2\n",
    "                    my_gap = (tA + bA) // 2\n",
    "                    circle_center = Point(mx_gap, my_gap)\n",
    "                    circle_shape = circle_center.buffer(10)\n",
    "                    in_roi = any(roi.intersects(circle_shape) for roi in self.rois)\n",
    "                    circle_color = (0, 0, 255) if in_roi else (128, 128, 200)\n",
    "                    cv2.circle(frame, (mx_gap, my_gap), 10, circle_color, 3)\n",
    "                    if in_roi:\n",
    "                        line_breaks_in_roi = True\n",
    "                        circle_in_roi_count += 1\n",
    "        return frame, line_breaks, line_breaks_in_roi, circle_in_roi_count\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        frame_960 = cv2.resize(frame, (960, 540))\n",
    "        k_val = cv2.getTrackbarPos(\"KSize\", self.window_name)\n",
    "        k_val = k_val + 1 if k_val % 2 == 0 else k_val\n",
    "        k_val = k_val if k_val > 0 else 1\n",
    "        manual_thr = cv2.getTrackbarPos(\"ThreshVal\", self.window_name)\n",
    "        base_frame = frame_960.copy()\n",
    "        full_blurred = cv2.GaussianBlur(base_frame, (21, 21), 0)\n",
    "        blurred = cv2.GaussianBlur(frame_960, (k_val, k_val), 5)\n",
    "        h, w = blurred.shape[:2]\n",
    "        data = blurred.reshape(-1, 3).astype(np.float32)\n",
    "        km = KMeans(n_clusters=2, random_state=42).fit(data)\n",
    "        labels = km.labels_.reshape(h, w)\n",
    "        centers = km.cluster_centers_\n",
    "        brightness = [0.114 * c[0] + 0.587 * c[1] + 0.299 * c[2] for c in centers]\n",
    "        darkest_cluster = np.argmin(brightness)\n",
    "        mask_kmeans = np.where(labels == darkest_cluster, 0, 255).astype(np.uint8)\n",
    "        gray_frame = cv2.cvtColor(frame_960, cv2.COLOR_BGR2GRAY)\n",
    "        _, mask_manual = cv2.threshold(gray_frame, manual_thr, 255, cv2.THRESH_BINARY_INV)\n",
    "        mask = cv2.bitwise_and(mask_kmeans, mask_manual)\n",
    "        white_pixels = int(np.sum(mask == 255))\n",
    "        black_pixels = int(np.sum(mask == 0))\n",
    "        total = white_pixels + black_pixels\n",
    "        white_percent = (white_pixels / total) * 100 if total > 0 else 0\n",
    "\n",
    "        if white_percent > 5:\n",
    "            is_paused = True\n",
    "            circle_in_roi_count = 0\n",
    "            is_broken = False\n",
    "            line_breaks_in_roi = False\n",
    "        else:\n",
    "            is_paused = False\n",
    "            _, is_broken, line_breaks_in_roi, circle_in_roi_count = self.detect_line_breaks_bbox_horizontal(base_frame, mask, gap_threshold=30)\n",
    "\n",
    "        roi_mask = np.zeros((base_frame.shape[0], base_frame.shape[1]), dtype=np.uint8)\n",
    "        for roi in self.rois:\n",
    "            pts = np.array(roi.exterior.coords, np.int32).reshape((-1, 1, 2))\n",
    "            cv2.fillPoly(roi_mask, [pts], 255)\n",
    "        inv_mask = cv2.bitwise_not(roi_mask)\n",
    "        inside_roi = cv2.bitwise_and(base_frame, base_frame, mask=roi_mask)\n",
    "        outside_roi = cv2.bitwise_and(full_blurred, full_blurred, mask=inv_mask)\n",
    "        final_frame = cv2.add(inside_roi, outside_roi)\n",
    "\n",
    "        if is_paused:\n",
    "            cvzone.putTextRect(final_frame, \"Detection Paused\", (10, 40), 1, 2, offset=5, colorR=(255, 0, 0), colorT=(255, 255, 255))\n",
    "        else:\n",
    "            if is_broken:\n",
    "                cvzone.putTextRect(final_frame, \"Frame : Skip Detected\", (10, 40), 1, 2, offset=5, colorR=(0, 255, 255), colorT=(0, 0, 0))\n",
    "            else:\n",
    "                cvzone.putTextRect(final_frame, \"Frame : Good\", (10, 40), 1, 2, offset=5, colorR=(0, 255, 0), colorT=(0, 0, 0))\n",
    "            if line_breaks_in_roi:\n",
    "                cvzone.putTextRect(final_frame, f\"ROI : Skip Detected ({circle_in_roi_count})\", (10, 65), 1, 2, offset=5, colorR=(0, 255, 255), colorT=(0, 0, 0))\n",
    "            else:\n",
    "                cvzone.putTextRect(final_frame, \"ROI : Good\", (10, 65), 1, 2, offset=5, colorR=(0, 255, 0), colorT=(0, 0, 0))\n",
    "        self.draw_rois(final_frame)\n",
    "\n",
    "        mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        mini_blurred = cv2.resize(blurred, (224, 126))\n",
    "        mini_mask = cv2.resize(mask_3ch, (224, 126))\n",
    "        H, W = final_frame.shape[:2]\n",
    "        hMini, wMini = mini_blurred.shape[:2]\n",
    "        final_frame[H - hMini : H, 0:wMini] = mini_blurred\n",
    "        final_frame[H - hMini : H, W - wMini : W] = mini_mask\n",
    "        cv2.rectangle(final_frame, (0, H - hMini), (wMini, H), (0, 255, 0), 2)\n",
    "        cv2.rectangle(final_frame, (W - wMini, H - hMini), (W, H), (0, 255, 0), 2)\n",
    "        cvzone.putTextRect(final_frame, f\"White: {white_pixels} ({white_percent:.4f}%)\", (10, 115), 1, 2, offset=5)\n",
    "        cvzone.putTextRect(final_frame, f\"Black: {black_pixels}\", (10, 140), 1, 2, offset=5)\n",
    "        return final_frame\n",
    "\n",
    "    def run(self):\n",
    "        frame = cv2.imread(self.image_file)\n",
    "        if frame is None:\n",
    "            print(\"Error loading image\")\n",
    "            return\n",
    "        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(self.window_name, self.window_size)\n",
    "        cv2.createTrackbar(\"KSize\", self.window_name, 15, 31, lambda x: None)\n",
    "        cv2.createTrackbar(\"ThreshVal\", self.window_name, 128, 255, lambda x: None)\n",
    "        while True:\n",
    "            frame_processed = self.process_frame(frame)\n",
    "            cv2.imshow(self.window_name, frame_processed)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key in [ord(\"q\"), 27]:\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_file = r\"C:\\xampp\\htdocs\\VISUALAI\\website-django\\inspection\\src\\core\\img\\lighting.jpg\"\n",
    "    sd = SkipDetector(image_file=image_file, camera_name=\"Nana\")\n",
    "    sd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
